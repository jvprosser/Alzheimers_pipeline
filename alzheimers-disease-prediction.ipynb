{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8668279,"sourceType":"datasetVersion","datasetId":5194699}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-20T09:48:45.007459Z","iopub.execute_input":"2024-06-20T09:48:45.008017Z","iopub.status.idle":"2024-06-20T09:48:45.050022Z","shell.execute_reply.started":"2024-06-20T09:48:45.007976Z","shell.execute_reply":"2024-06-20T09:48:45.048672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/alzheimers-disease-dataset/alzheimers_disease_data.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:48:45.052389Z","iopub.execute_input":"2024-06-20T09:48:45.052927Z","iopub.status.idle":"2024-06-20T09:48:45.076752Z","shell.execute_reply.started":"2024-06-20T09:48:45.052883Z","shell.execute_reply":"2024-06-20T09:48:45.075745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Exploring the Dataframe**","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:48:45.078363Z","iopub.execute_input":"2024-06-20T09:48:45.079501Z","iopub.status.idle":"2024-06-20T09:48:45.105696Z","shell.execute_reply.started":"2024-06-20T09:48:45.079454Z","shell.execute_reply":"2024-06-20T09:48:45.104547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_df_info(df):\n    print(\"\\n\\033[1mShape of DataFrame:\\033[0m \", df.shape)\n    print(\"\\n\\033[1mColumns in DataFrame:\\033[0m \", df.columns.to_list())\n    print(\"\\n\\033[1mData types of columns:\\033[0m\\n\", df.dtypes)\n    \n    print(\"\\n\\033[1mInformation about DataFrame:\\033[0m\")\n    df.info()\n    \n    print(\"\\n\\033[1mNumber of unique values in each column:\\033[0m\")\n    for col in df.columns:\n        print(f\"\\033[1m{col}\\033[0m: {df[col].nunique()}\")\n        \n    print(\"\\n\\033[1mNumber of null values in each column:\\033[0m\\n\", df.isnull().sum())\n    \n    print(\"\\n\\033[1mNumber of duplicate rows:\\033[0m \", df.duplicated().sum())\n    \n    print(\"\\n\\033[1mDescriptive statistics of DataFrame:\\033[0m\\n\", df.describe().transpose())\n\n# Call the function\nget_df_info(df)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:48:45.108436Z","iopub.execute_input":"2024-06-20T09:48:45.108901Z","iopub.status.idle":"2024-06-20T09:48:45.212049Z","shell.execute_reply.started":"2024-06-20T09:48:45.108861Z","shell.execute_reply":"2024-06-20T09:48:45.210776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['PatientID','DoctorInCharge'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:48:45.213432Z","iopub.execute_input":"2024-06-20T09:48:45.213833Z","iopub.status.idle":"2024-06-20T09:48:45.221573Z","shell.execute_reply.started":"2024-06-20T09:48:45.213788Z","shell.execute_reply":"2024-06-20T09:48:45.220278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:48:45.223407Z","iopub.execute_input":"2024-06-20T09:48:45.224381Z","iopub.status.idle":"2024-06-20T09:48:45.232609Z","shell.execute_reply.started":"2024-06-20T09:48:45.224334Z","shell.execute_reply":"2024-06-20T09:48:45.231403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the correlation matrix\ncorr = df.corr(numeric_only=True)\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:48:45.234366Z","iopub.execute_input":"2024-06-20T09:48:45.234897Z","iopub.status.idle":"2024-06-20T09:48:46.082291Z","shell.execute_reply.started":"2024-06-20T09:48:45.23485Z","shell.execute_reply":"2024-06-20T09:48:46.080999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **From the Correlation Heatmap we can see that 'MMSE', 'ADL', 'FunctionalAssessment', 'MemoryComplaints', 'BehavioralProblems' has high Correlation with Diagnosis**","metadata":{}},{"cell_type":"markdown","source":"# **Machine Learning**","metadata":{}},{"cell_type":"code","source":"# Divide the dataframe into features (X) and target (y)\nX = df.drop('Diagnosis', axis=1)\ny = df['Diagnosis']","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:48:46.083929Z","iopub.execute_input":"2024-06-20T09:48:46.084315Z","iopub.status.idle":"2024-06-20T09:48:46.091731Z","shell.execute_reply.started":"2024-06-20T09:48:46.084281Z","shell.execute_reply":"2024-06-20T09:48:46.090392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import f1_score\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import VotingClassifier, StackingClassifier","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:48:46.094528Z","iopub.execute_input":"2024-06-20T09:48:46.095127Z","iopub.status.idle":"2024-06-20T09:48:46.104547Z","shell.execute_reply.started":"2024-06-20T09:48:46.095089Z","shell.execute_reply":"2024-06-20T09:48:46.103127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_models(X, y):\n    # Split the data into training and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    # Check for class imbalance\n    class_counts = np.bincount(y_train)\n    if len(class_counts) > 2 or np.min(class_counts) / np.max(class_counts) < 0.1:\n      print(\"Class imbalance detected. Applying SMOTE...\")\n    \n    # Apply SMOTE (class imbalance)\n    smote = SMOTE(random_state=42)\n    X_train, y_train = smote.fit_resample(X_train, y_train)\n    \n    # Initialize the StandardScaler\n    scaler = StandardScaler()\n\n    # Fit the scaler on the training data and transform both training and test data\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n\n    # Define the models\n    models = {\n        'LogisticRegression': LogisticRegression(),\n        'SVC': SVC(),\n        'DecisionTree': DecisionTreeClassifier(),\n        'RandomForest': RandomForestClassifier(),\n        'ExtraTrees': ExtraTreesClassifier(),\n        'AdaBoost': AdaBoostClassifier(),\n        'GradientBoost': GradientBoostingClassifier(),\n        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n        'LightGBM': LGBMClassifier(),\n        'CatBoost': CatBoostClassifier(verbose=0)\n    }\n\n    # Initialize a dictionary to hold the performance of each model\n    model_performance = {}\n\n    # Apply each model\n    for model_name, model in models.items():\n        print(f\"\\n\\033[1mClassification with {model_name}:\\033[0m\\n{'-' * 30}\")\n        \n        # Fit the model to the training data\n        model.fit(X_train, y_train)\n\n        # Make predictions on the test data\n        y_pred = model.predict(X_test)\n\n        # Calculate the accuracy and f1 score\n        accuracy = accuracy_score(y_test, y_pred)\n        f1 = f1_score(y_test, y_pred, average='weighted')\n\n        # Store the performance in the dictionary\n        model_performance[model_name] = (accuracy, f1)\n\n        # Print the accuracy score\n        print(\"\\033[1m**Accuracy**:\\033[0m\\n\", accuracy)\n\n        # Print the confusion matrix\n        print(\"\\n\\033[1m**Confusion Matrix**:\\033[0m\\n\", confusion_matrix(y_test, y_pred))\n\n        # Print the classification report\n        print(\"\\n\\033[1m**Classification Report**:\\033[0m\\n\", classification_report(y_test, y_pred))\n\n    # Sort the models based on f1 score and pick the top 3\n    top_3_models = sorted(model_performance.items(), key=lambda x: x[1][1], reverse=True)[:3]\n    print(\"\\n\\033[1mTop 3 Models based on F1 Score:\\033[0m\\n\", top_3_models)\n\n    # Extract the model names and classifiers for the top 3 models\n    top_3_model_names = [model[0] for model in top_3_models]\n    top_3_classifiers = [models[model_name] for model_name in top_3_model_names]\n\n    # Create a Voting Classifier with the top 3 models\n    print(\"\\n\\033[1mInitializing Voting Classifier with top 3 models...\\033[0m\\n\")\n    voting_clf = VotingClassifier(estimators=list(zip(top_3_model_names, top_3_classifiers)), voting='hard')\n    voting_clf.fit(X_train, y_train)\n    y_pred = voting_clf.predict(X_test)\n    print(\"\\n\\033[1m**Voting Classifier Evaluation**:\\033[0m\\n\")\n    print(\"\\033[1m**Accuracy**:\\033[0m\\n\", accuracy_score(y_test, y_pred))\n    print(\"\\n\\033[1m**Confusion Matrix**:\\033[0m\\n\", confusion_matrix(y_test, y_pred))\n    print(\"\\n\\033[1m**Classification Report**:\\033[0m\\n\", classification_report(y_test, y_pred))\n\n    # Create a Stacking Classifier with the top 3 models\n    print(\"\\n\\033[1mInitializing Stacking Classifier with top 3 models...\\033[0m\\n\")\n    stacking_clf = StackingClassifier(estimators=list(zip(top_3_model_names, top_3_classifiers)))\n    stacking_clf.fit(X_train, y_train)\n    y_pred = stacking_clf.predict(X_test)\n    print(\"\\n\\033[1m**Stacking Classifier Evaluation**:\\033[0m\\n\")\n    print(\"\\033[1m**Accuracy**:\\033[0m\\n\", accuracy_score(y_test, y_pred))\n    print(\"\\n\\033[1m**Confusion Matrix**:\\033[0m\\n\", confusion_matrix(y_test, y_pred))\n    print(\"\\n\\033[1m**Classification Report**:\\033[0m\\n\", classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:48:46.106417Z","iopub.execute_input":"2024-06-20T09:48:46.106944Z","iopub.status.idle":"2024-06-20T09:48:46.130743Z","shell.execute_reply.started":"2024-06-20T09:48:46.106899Z","shell.execute_reply":"2024-06-20T09:48:46.129205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"apply_models(X, y)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:48:46.132622Z","iopub.execute_input":"2024-06-20T09:48:46.13319Z","iopub.status.idle":"2024-06-20T09:49:29.151151Z","shell.execute_reply.started":"2024-06-20T09:48:46.133143Z","shell.execute_reply":"2024-06-20T09:49:29.149786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **From the Correlation Heatmap we can see that 'MMSE', 'ADL', 'FunctionalAssessment', 'MemoryComplaints', 'BehavioralProblems' has high Correlation with Diagnosis. So we will choose this features only for the model and see How the score changes.**","metadata":{}},{"cell_type":"code","source":"# Select features you want to use\nfeatures = ['MMSE', 'ADL', 'FunctionalAssessment', 'MemoryComplaints', 'BehavioralProblems']\nX = df[features]  # Select features from DataFrame","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:49:29.153208Z","iopub.execute_input":"2024-06-20T09:49:29.153728Z","iopub.status.idle":"2024-06-20T09:49:29.161081Z","shell.execute_reply.started":"2024-06-20T09:49:29.153676Z","shell.execute_reply":"2024-06-20T09:49:29.159701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"apply_models(X, y)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T09:49:29.162824Z","iopub.execute_input":"2024-06-20T09:49:29.163312Z","iopub.status.idle":"2024-06-20T09:49:50.402591Z","shell.execute_reply.started":"2024-06-20T09:49:29.163269Z","shell.execute_reply":"2024-06-20T09:49:50.401362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **There is a slight increase in the Accuracy and F1-Scores of the model**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}